{
  "providers": [
    {
      "key": "openai",
      "name": "OpenAI",
      "description": "OpenAI's GPT models including GPT-4 and GPT-3.5",
      "defaultEndpoint": "https://api.openai.com/v1",
      "requiresApiKey": true,
      "supportsStreaming": true,
      "supportsVision": true,
      "supportsFunctions": true,
      "supportsToolUse": true,
      "models": [
        {
          "id": "gpt-4",
          "name": "GPT-4",
          "description": "Most capable model, best for complex tasks",
          "contextWindow": 8192,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.03,
          "outputCostPer1KTokens": 0.06,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": true
        },
        {
          "id": "gpt-4-32k",
          "name": "GPT-4 32K",
          "description": "GPT-4 with extended context window",
          "contextWindow": 32768,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.06,
          "outputCostPer1KTokens": 0.12,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": true
        },
        {
          "id": "gpt-4-turbo-preview",
          "name": "GPT-4 Turbo",
          "description": "GPT-4 with 128K context and vision",
          "contextWindow": 128000,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.01,
          "outputCostPer1KTokens": 0.03,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": true
        },
        {
          "id": "gpt-3.5-turbo",
          "name": "GPT-3.5 Turbo",
          "description": "Fast and cost-effective for most tasks",
          "contextWindow": 16385,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.0005,
          "outputCostPer1KTokens": 0.0015,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": true
        }
      ]
    },
    {
      "key": "anthropic",
      "name": "Anthropic",
      "description": "Claude models with extended context and strong reasoning",
      "defaultEndpoint": "https://api.anthropic.com/v1",
      "requiresApiKey": true,
      "supportsStreaming": true,
      "supportsVision": true,
      "supportsFunctions": false,
      "supportsToolUse": true,
      "models": [
        {
          "id": "claude-3-opus-20240229",
          "name": "Claude 3 Opus",
          "description": "Most powerful Claude model for complex tasks",
          "contextWindow": 200000,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.015,
          "outputCostPer1KTokens": 0.075,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        },
        {
          "id": "claude-3-sonnet-20240229",
          "name": "Claude 3 Sonnet",
          "description": "Balanced performance and speed",
          "contextWindow": 200000,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.003,
          "outputCostPer1KTokens": 0.015,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        },
        {
          "id": "claude-3-5-sonnet-20240620",
          "name": "Claude 3.5 Sonnet",
          "description": "Enhanced Sonnet with improved capabilities",
          "contextWindow": 200000,
          "maxOutputTokens": 8192,
          "inputCostPer1KTokens": 0.003,
          "outputCostPer1KTokens": 0.015,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        },
        {
          "id": "claude-3-haiku-20240307",
          "name": "Claude 3 Haiku",
          "description": "Fast and cost-effective for simple tasks",
          "contextWindow": 200000,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0.00025,
          "outputCostPer1KTokens": 0.00125,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        }
      ]
    },
    {
      "key": "google",
      "name": "Google",
      "description": "Google's Gemini models with multimodal capabilities",
      "defaultEndpoint": "https://generativelanguage.googleapis.com/v1",
      "requiresApiKey": true,
      "supportsStreaming": true,
      "supportsVision": true,
      "supportsFunctions": false,
      "supportsToolUse": false,
      "models": [
        {
          "id": "gemini-pro",
          "name": "Gemini Pro",
          "description": "Best for text-only tasks",
          "contextWindow": 32760,
          "maxOutputTokens": 8192,
          "inputCostPer1KTokens": 0.0005,
          "outputCostPer1KTokens": 0.0015,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": false
        },
        {
          "id": "gemini-pro-vision",
          "name": "Gemini Pro Vision",
          "description": "Multimodal model for text and images",
          "contextWindow": 16384,
          "maxOutputTokens": 2048,
          "inputCostPer1KTokens": 0.0005,
          "outputCostPer1KTokens": 0.0015,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        },
        {
          "id": "gemini-1.5-pro",
          "name": "Gemini 1.5 Pro",
          "description": "Extended context window up to 1M tokens",
          "contextWindow": 1048576,
          "maxOutputTokens": 8192,
          "inputCostPer1KTokens": 0.0035,
          "outputCostPer1KTokens": 0.0105,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        },
        {
          "id": "gemini-1.5-flash",
          "name": "Gemini 1.5 Flash",
          "description": "Fast model with 1M token context",
          "contextWindow": 1048576,
          "maxOutputTokens": 8192,
          "inputCostPer1KTokens": 0.00035,
          "outputCostPer1KTokens": 0.00105,
          "supportsStreaming": true,
          "supportsVision": true,
          "supportsFunctions": false
        }
      ]
    },
    {
      "key": "meta",
      "name": "Meta AI",
      "description": "Open-source Llama models for self-hosted deployment",
      "defaultEndpoint": "http://localhost:8080/v1",
      "requiresApiKey": false,
      "supportsStreaming": true,
      "supportsVision": false,
      "supportsFunctions": false,
      "supportsToolUse": true,
      "models": [
        {
          "id": "llama-3-8b",
          "name": "Llama 3 8B",
          "description": "Efficient open-source model",
          "contextWindow": 8192,
          "maxOutputTokens": 2048,
          "inputCostPer1KTokens": 0,
          "outputCostPer1KTokens": 0,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": false,
          "metadata": {
            "isOpenSource": true,
            "selfHosted": true
          }
        },
        {
          "id": "llama-3-70b",
          "name": "Llama 3 70B",
          "description": "Powerful open-source model",
          "contextWindow": 8192,
          "maxOutputTokens": 2048,
          "inputCostPer1KTokens": 0,
          "outputCostPer1KTokens": 0,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": false,
          "metadata": {
            "isOpenSource": true,
            "selfHosted": true
          }
        },
        {
          "id": "llama-3.1-8b",
          "name": "Llama 3.1 8B",
          "description": "Extended context with tool use",
          "contextWindow": 131072,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0,
          "outputCostPer1KTokens": 0,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": false,
          "metadata": {
            "isOpenSource": true,
            "selfHosted": true
          }
        },
        {
          "id": "llama-3.1-70b",
          "name": "Llama 3.1 70B",
          "description": "Extended context, powerful reasoning",
          "contextWindow": 131072,
          "maxOutputTokens": 4096,
          "inputCostPer1KTokens": 0,
          "outputCostPer1KTokens": 0,
          "supportsStreaming": true,
          "supportsVision": false,
          "supportsFunctions": false,
          "metadata": {
            "isOpenSource": true,
            "selfHosted": true
          }
        }
      ]
    }
  ],
  "features": {
    "maxConcurrentRequests": 5,
    "defaultTimeout": 60000,
    "defaultRetryAttempts": 3,
    "defaultRetryDelay": 1000,
    "enableRateLimiting": true,
    "enableCostTracking": true,
    "enableTokenCounting": true
  },
  "rateLimits": {
    "openai": {
      "requestsPerMinute": 3500,
      "tokensPerMinute": 90000,
      "requestsPerDay": 10000
    },
    "anthropic": {
      "requestsPerMinute": 50,
      "tokensPerMinute": 40000,
      "requestsPerDay": null
    },
    "google": {
      "requestsPerMinute": 60,
      "tokensPerMinute": 32000,
      "requestsPerDay": null
    },
    "meta": {
      "requestsPerMinute": null,
      "tokensPerMinute": null,
      "requestsPerDay": null
    }
  }
}
